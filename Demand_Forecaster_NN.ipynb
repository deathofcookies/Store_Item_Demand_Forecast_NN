{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One hot encode data (Complete)\n",
    "- Rework windowing function (Complete)\n",
    "- Fix Neural Network to work with OHE Data (Complete)\n",
    "- Include SMAPE in Neural Network (Complete)\n",
    "- Work on forecasting portion (Complete)\n",
    "- Try another LSTM Layer (Complete. Didn't really improve the model)\n",
    "- Increase Window Size (Complete. Didn't really improve the model)\n",
    "- Expand dataset so that it includes all stores and items (500 trendlines) (Complete)\n",
    "- Optimize neural network. Consider using Conv1D layer? Another LSTM layer? (Complete)\n",
    "- Maybe try an encoder-decoder system\n",
    "- Run and submit data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demand forecaster for the kaggle competition at https://www.kaggle.com/c/demand-forecasting-kernels-only using a LSTM neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch as torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data\n",
    "\n",
    "path_in = './data/'\n",
    "train_cols = ['date', 'store', 'item', 'sales']\n",
    "train_dtypes = {'date': 'str', 'store': 'int', 'item': 'int', 'sales': 'int'}\n",
    "parse_dates = ['date']\n",
    "\n",
    "test_cols = ['date', 'store', 'item']\n",
    "test_dtypes = {'date': 'str', 'store': 'int', 'item': 'int'}\n",
    "\n",
    "\n",
    "train = pd.read_csv(path_in + 'train.csv', dtype = train_dtypes, parse_dates = parse_dates)\n",
    "test = pd.read_csv(path_in + 'test.csv', dtype = test_dtypes, parse_dates = parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>396838</td>\n",
       "      <td>2014-08-20</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407927</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28278</td>\n",
       "      <td>2015-06-08</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555868</td>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73182</td>\n",
       "      <td>2013-05-23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127429</td>\n",
       "      <td>2016-12-06</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753311</td>\n",
       "      <td>2015-09-27</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>669693</td>\n",
       "      <td>2016-10-09</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>721017</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740905</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  store  item  sales\n",
       "396838 2014-08-20      8    22    102\n",
       "407927 2014-12-31      4    23     17\n",
       "28278  2015-06-08      6     2     44\n",
       "555868 2015-02-04      5    31     15\n",
       "73182  2013-05-23      1     5     24\n",
       "127429 2016-12-06     10     7     49\n",
       "753311 2015-09-27      3    42     62\n",
       "669693 2016-10-09      7    37     23\n",
       "721017 2017-04-23      5    40     23\n",
       "740905 2016-10-07      6    41      7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 10 stores with 50 different products. The sales for each item range between 0 and 231, but they are mainly around the 30-70 range. There is five years worth of sales data (2013-2017) to train on and the goal is the predict the sales for the next 3 months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Here we create a windowed dataset to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include other date information to be processed\n",
    "train['day_of_week'] = train['date'].dt.dayofweek\n",
    "train['month'] = train['date'].dt.month\n",
    "train['year'] = train['date'].dt.year - 2013 # Subtract earliest year to help normalize this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode data\n",
    "columns_OHE = train.columns[((train.columns != 'sales') & (train.columns != 'date')) & (train.columns != 'year')]\n",
    "train_OHE = pd.get_dummies(train, columns = columns_OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHE_cols = train_OHE.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_windows(df, width):\n",
    "    \"\"\"\n",
    "    Function: Takes in the DataFrame, df, and splits it into rolling windows of size width to be used in a neural network.\n",
    "    It outputs a dataframe and a target dataframe, which is the sales number to be predicted. The other information such\n",
    "    as year, day of the week, are all taken from the target.\n",
    "    Inputs: df - dataframe with columns [date, store, item, sales]\n",
    "            width - the with of the window including the last sales data which will be the target\n",
    "    Outputs: df_windowed - dataframe with the day of the week of the last day of the window, the store, and item numbers\n",
    "                            along with the windowed sales data\n",
    "             df_target - dataframe that contains the target date and target sales\n",
    "    \"\"\"\n",
    "    # Retrieve column names that are not date nor sales\n",
    "    other_columns = df.columns[((df.columns != 'sales') & (df.columns != 'date'))]\n",
    "    \n",
    "    # Initalize output datasets\n",
    "    windowed_data = np.empty([len(df)-width+1, width - 1])\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    # Create windows. E.g. [1, 2, 3, 4, 5, 6, 7] -> [[1,2,3,4], [2,3,4,5], [3,4,5,6]]\n",
    "    # Also creates targets which would be [[5], [6], [7]] in the above case\n",
    "    for i in range(len(df)-width+1):\n",
    "        windowed_data[i] = list(df.iloc[i:i+width-1]['sales'])\n",
    "        \n",
    "        \n",
    "    # Create a DataFrame to contain the windowed data\n",
    "    windowed_columns = list(map(str,(range(1,width))))\n",
    "    \n",
    "    df_temp = pd.DataFrame(data = windowed_data, \n",
    "                               columns = windowed_columns,\n",
    "                               dtype = 'int')\n",
    "    # Create a DataFrame containing store, year, etc. information and combine with windowed data\n",
    "    df_other = df.loc[width-1::, other_columns].reset_index(drop = True)\n",
    "    \n",
    "    df_windowed = pd.concat([df_temp, df_other], axis = 1)\n",
    "    \n",
    "    # Create target dataset\n",
    "    df_target = pd.DataFrame(data = df.loc[width-1::, ['date', 'sales']]).reset_index(drop = True)\n",
    "        \n",
    "    return df_windowed, df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Using only a part of the data set. Otherwise use stores 1-10 and items 1-50\n",
    "stores = list(range(1, 11))\n",
    "items = list(range(1,51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windowing Data\n",
    "window_size = 30\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df_target = pd.DataFrame()\n",
    "\n",
    "for store_num in stores:\n",
    "    for item_num in items:\n",
    "        # Calculate windows\n",
    "        sample = train_OHE.loc[(train['store'] == store_num) & (train['item'] == item_num) & (train['year'] <= 3)]\n",
    "        df_temp, df_target_temp = create_data_windows(sample, window_size + 1)\n",
    "        \n",
    "        # Append to dataset\n",
    "        df = pd.concat([df, df_temp], axis = 0)\n",
    "        df_target = pd.concat([df_target, df_target_temp], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_df, val_df, train_target_df, val_target_df = train_test_split(df, df_target, test_size=0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1419</td>\n",
       "      <td>63</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>72</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>547</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>77</td>\n",
       "      <td>68</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>52</td>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>30</td>\n",
       "      <td>58</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>74</td>\n",
       "      <td>90</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>90</td>\n",
       "      <td>101</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>122</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>99</td>\n",
       "      <td>122</td>\n",
       "      <td>106</td>\n",
       "      <td>128</td>\n",
       "      <td>125</td>\n",
       "      <td>77</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1255</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1208</td>\n",
       "      <td>91</td>\n",
       "      <td>120</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>101</td>\n",
       "      <td>119</td>\n",
       "      <td>101</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643950 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1    2   3    4    5    6    7    8    9   10  ...  month_3  month_4  \\\n",
       "1419   63   47  57   50   72   63   61   56   40   36  ...        0        0   \n",
       "547    40   31  45   47   48   38   36   44   41   39  ...        0        0   \n",
       "153    23   22  35   26   35   23   45   26   31   18  ...        0        0   \n",
       "372    23   27  37   44   41   20   20   33   34   27  ...        0        0   \n",
       "980    68   69  77   68   84   77   52   58   57   77  ...        0        0   \n",
       "...   ...  ...  ..  ...  ...  ...  ...  ...  ...  ...  ...      ...      ...   \n",
       "545    30   58  71   64   48   74   90   41   56   66  ...        0        0   \n",
       "485    66   64  90  101   50   65   59   68   70   75  ...        0        0   \n",
       "880   122   90  80   99  122  106  128  125   77  122  ...        0        0   \n",
       "1255   36   41  44   41   25   27   42   35   36   43  ...        0        0   \n",
       "1208   91  120  65   66   82   82  101  119  101   80  ...        0        0   \n",
       "\n",
       "      month_5  month_6  month_7  month_8  month_9  month_10  month_11  \\\n",
       "1419        0        0        0        0        0         0         0   \n",
       "547         0        0        0        1        0         0         0   \n",
       "153         0        0        1        0        0         0         0   \n",
       "372         0        0        0        0        0         0         0   \n",
       "980         0        0        0        0        0         1         0   \n",
       "...       ...      ...      ...      ...      ...       ...       ...   \n",
       "545         0        0        1        0        0         0         0   \n",
       "485         1        0        0        0        0         0         0   \n",
       "880         0        1        0        0        0         0         0   \n",
       "1255        0        0        1        0        0         0         0   \n",
       "1208        1        0        0        0        0         0         0   \n",
       "\n",
       "      month_12  \n",
       "1419         1  \n",
       "547          0  \n",
       "153          0  \n",
       "372          0  \n",
       "980          0  \n",
       "...        ...  \n",
       "545          0  \n",
       "485          0  \n",
       "880          0  \n",
       "1255         0  \n",
       "1208         0  \n",
       "\n",
       "[643950 rows x 110 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1419</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>547</td>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>2013-07-03</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>2014-02-07</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2015-10-08</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545</td>\n",
       "      <td>2014-07-30</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>2014-05-31</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1255</td>\n",
       "      <td>2016-07-09</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1208</td>\n",
       "      <td>2016-05-23</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643950 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  sales\n",
       "1419 2016-12-20     39\n",
       "547  2014-08-01     31\n",
       "153  2013-07-03     27\n",
       "372  2014-02-07     52\n",
       "980  2015-10-08     78\n",
       "...         ...    ...\n",
       "545  2014-07-30     53\n",
       "485  2014-05-31     74\n",
       "880  2015-06-30     94\n",
       "1255 2016-07-09     40\n",
       "1208 2016-05-23     76\n",
       "\n",
       "[643950 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn dataframes into tensors to prepare them to be fed into neural network in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = torch.utils.data.TensorDataset(torch.FloatTensor(np.array(train_df)), torch.FloatTensor(np.array(train_target_df['sales'])))\n",
    "validation_dataset = torch.utils.data.TensorDataset(torch.FloatTensor(np.array(val_df)), torch.FloatTensor(np.array(val_target_df['sales'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initalize Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias,0)\n",
    "        \n",
    "def SMAPE(y_true, y_pred):\n",
    "    \"\"\" Returns the standard mean absolute percent error in %\n",
    "    \"\"\"\n",
    "    return np.mean(200*np.abs(y_pred - y_true)/(np.abs(y_pred)+np.abs(y_true)))\n",
    "        \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_cols, window_length, n_hidden_1=32, n_hidden_2=32, n_hidden_3=32, n_hidden_4 = 32, D_out=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.window_length = window_length\n",
    "        self.num_cols = num_cols\n",
    "        \n",
    "        # LSTM Layer\n",
    "        self.lstm1 = nn.LSTM(1, n_hidden_1, bidirectional = False, batch_first = True)\n",
    "        \n",
    "        # Densely Connected Layers\n",
    "        self.fc1 = nn.Linear(n_hidden_1 + num_cols - self.window_length, n_hidden_2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(n_hidden_2, n_hidden_3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(n_hidden_3, D_out)\n",
    "        self.out_act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Split input tensor. x_seq will be fed into the lstm.\n",
    "        x_seq, x_info = x[:,:self.window_length], x[:,self.window_length:]\n",
    "        \n",
    "        # LSTM layer\n",
    "        x_seq = torch.unsqueeze(x_seq, 2)\n",
    "        lstm_out, (h, c) = self.lstm1(x_seq)\n",
    "        \n",
    "        # Combine the extra info to the lstm results using the output of the last lstm neuron\n",
    "        lstm_output = torch.squeeze(lstm_out[:,-1,:], dim = 1)\n",
    "        \n",
    "        combined_out = torch.cat([lstm_output, x_info], 1)\n",
    "        \n",
    "        # Fully connected layer 1\n",
    "        fc1_out = self.fc1(combined_out)\n",
    "        fc1_out = self.relu1(fc1_out)\n",
    "        \n",
    "        # Fully connected layer 2\n",
    "        fc2_out = self.fc2(fc1_out)\n",
    "        fc2_out = self.relu2(fc2_out)\n",
    "        \n",
    "        # Output layer\n",
    "        y = self.out_act(self.fc3(fc2_out))\n",
    "        \n",
    "        # Squeeze to remove extra dimensions of size 1\n",
    "        return torch.squeeze(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_set, model, criterion, train_loader, validation_loader, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    loss_accuracy = {'training_loss':[], 'validation_loss':[],'validation_smape':[], 'validation_precision':[], 'validation_recall':[]}\n",
    "    \n",
    "    training_size = (len(list(train_loader))-1)*len(list(train_loader)[0][0]) + len(list(train_loader)[-1][0])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        #clear_output(wait=True)\n",
    "        print(\"Epoch {} / {}\\n=============\".format(epoch+1, epochs))\n",
    "            \n",
    "        train_smape_sum = 0\n",
    "        train_loss_sum = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            ## Forward pass\n",
    "            yhat = model(x)\n",
    "            ## Compute loss\n",
    "            train_loss = criterion(yhat, y)\n",
    "            train_loss_sum += train_loss.item() * len(x)\n",
    "            ## Compute gradient in backward pass\n",
    "            train_loss.backward()\n",
    "            ## Update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_smape_sum += SMAPE(y.numpy(), yhat.detach().numpy()) * len(x)\n",
    "            \n",
    "            \n",
    "         \n",
    "        ## Compute validation accuracy\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        for x, y in validation_loader:\n",
    "            yhat = net(x)\n",
    "            val_loss = criterion(yhat, y)                     \n",
    "            val_smape = SMAPE(y.numpy(), yhat.detach().numpy())\n",
    "            \n",
    "        # Calculate loss values\n",
    "        train_loss_avg = train_loss_sum / training_size\n",
    "        train_smape = train_smape_sum / training_size\n",
    "        \n",
    "        # Append values to loss_accuracy to save results\n",
    "        loss_accuracy['training_loss'].append(train_loss_avg)\n",
    "        \n",
    "        loss_accuracy['validation_loss'].append(val_loss.item())\n",
    "        loss_accuracy['validation_smape'].append(val_smape)\n",
    "        \n",
    "        \n",
    "        ## Print training loss and accuracy, and validation accuracy\n",
    "        \n",
    "        print(\"Training mean squared error: {:.3f} | Training SMAPE: {:.2f}\\nValidation mean squared error: {:.3f} | Validation SMAPE: {:.2f}\".format(\n",
    "            train_loss_avg, train_smape, val_loss.item(), val_smape))\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        ## Add precision and recall\n",
    "        \n",
    "    print(\"Training complete!\")\n",
    "                \n",
    "    return loss_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "\n",
    "## Network dimensions\n",
    "num_cols = len(train_df.columns)\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 128\n",
    "n_hidden_3 = 64\n",
    "D_out = 1\n",
    "batch_size = 512\n",
    "reg_lambda = 0.005\n",
    "momentum_coef = 0.9\n",
    "dropout_percent = 0.0\n",
    "\n",
    "## Load data\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset), shuffle=False)\n",
    "\n",
    "## Initialize model\n",
    "net = Net(num_cols, window_size, n_hidden_1, n_hidden_2, n_hidden_3, D_out)\n",
    "net.apply(weights_init)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay = reg_lambda)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 12\n",
      "=============\n",
      "Training mean squared error: 257.637 | Training SMAPE: 23.24\n",
      "Validation mean squared error: 55.865 | Validation SMAPE: 13.06\n",
      "Epoch 2 / 12\n",
      "=============\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-31c8936dcd1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-0c9696a7e56b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(data_set, model, criterion, train_loader, validation_loader, optimizer, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m## Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;31m## Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-b789b86d3ca9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# LSTM layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Combine the extra info to the lstm results using the output of the last lstm neuron\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 559\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 12\n",
    "## Train the model\n",
    "loss_accuracy = train_model(training_dataset, net, criterion, train_loader, validation_loader, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots\n",
    "fig = plt.figure(1)\n",
    "plt.plot(loss_accuracy['training_loss'], color=\"red\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss [-]\")\n",
    "\n",
    "fig = plt.figure(2)\n",
    "plt.plot(loss_accuracy['validation_smape'], color=\"blue\")\n",
    "plt.title(\"Validation SMAPE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation SMAPE [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, df, start_date, end_date, store_num, item_num, col_names):\n",
    "    \"\"\"\n",
    "    This function creates a loop to forecast sales data into the future.\n",
    "    Inputs: model: The trained neural network model (pytorch model)\n",
    "            df: The dataframe containing the known past sequence data (dataframe)\n",
    "            start_date: The first forecast date (datetime string)\n",
    "            end_date: The last forecast date (datetime string)\n",
    "            store_num: the store number (int)\n",
    "            item_num: the item num (int)\n",
    "            col_names: the names of the columns fed into the neural network to ensure that they are ordered properly (list of strings)\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval() # Ensure that the model is in evaluation mode\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "    columns_OHE = df.columns[((train.columns != 'sales') & (train.columns != 'date')) & (train.columns != 'year')]\n",
    "    \n",
    "    #Initialize data\n",
    "    current_date = start_date\n",
    "    sales_seq = list(df.loc[(df['date'] >= (start_date - datetime.timedelta(days = window_size)))\n",
    "                               & (df['date'] < start_date)\n",
    "                               & (df['store'] == store_num)\n",
    "                               & (df['item'] == item_num),'sales'])\n",
    "\n",
    "    predictions = pd.DataFrame({'date': [], 'sales': [], 'store': [], 'item': []})\n",
    "    \n",
    "    # Count number of times the loop has to run\n",
    "    dates = pd.date_range(start = start_date, end = end_date, freq = 'D')\n",
    "\n",
    "    for i in range(len(dates)):\n",
    "        # Initialize store, date, and item data inputs to neural network\n",
    "        df_misc_info = pd.DataFrame({'date': [current_date], 'item': [item_num], 'store': [store_num]})\n",
    "        df_misc_info['date'] = pd.to_datetime(df_misc_info['date'], errors = 'coerce')\n",
    "        df_misc_info['day_of_week'] = df_misc_info['date'].dt.dayofweek\n",
    "        df_misc_info['month'] = df_misc_info['date'].dt.month\n",
    "        df_misc_info['year'] = df_misc_info['date'].dt.year - 2013\n",
    "\n",
    "        # Initialize sequential data\n",
    "        windowed_columns = list(map(str,(range(1,window_size+1))))\n",
    "        df_seq = pd.DataFrame(data = [sales_seq], \n",
    "                                   columns = windowed_columns,\n",
    "                                   dtype = 'int')\n",
    "\n",
    "        # Combine input data and ensure columns match\n",
    "        df_input = pd.concat([df_seq, df_misc_info], axis = 1)\n",
    "        df_input_OHE = pd.get_dummies(df_input, columns = columns_OHE)\n",
    "        df_input_OHE = df_input_OHE.reindex(columns = col_names).fillna(0)\n",
    "\n",
    "        # Forecast sales for next day\n",
    "        x = Variable(torch.FloatTensor(np.array(df_input_OHE)))\n",
    "        y = float(model(x))\n",
    "\n",
    "        # Append date and data\n",
    "        predictions = predictions.append({'date': current_date, 'sales': y,\n",
    "                                          'store': store_num, 'item': item_num}, ignore_index = True)\n",
    "\n",
    "        # Update sequence and date\n",
    "        sales_seq[:-1] = sales_seq[1::]\n",
    "        sales_seq[-1] = y\n",
    "\n",
    "        current_date = current_date + datetime.timedelta(days = 1)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('2017-01-01')\n",
    "end_date = pd.to_datetime('2017-03-31')\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "for store_num in stores:\n",
    "    for item_num in items:\n",
    "        predict_temp = model_forecast(net, train, start_date, end_date, store_num, item_num, df.columns)\n",
    "        predictions = pd.concat([predictions, predict_temp], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_num = 5\n",
    "item_num = 8\n",
    "\n",
    "predictions.loc[(predictions['store'] == store_num) & (predictions['item'] == item_num)].set_index(keys = ['date']).sort_index(ascending=True)['sales'].plot()\n",
    "val_set = train.loc[(train['store'] == store_num) & (train['item'] == item_num) \n",
    "                    & (train['date'] >= start_date) & (train['date'] <= end_date)]\n",
    "val_set.set_index(keys = ['date']).sort_index(ascending=True)['sales'].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = train.loc[(train['store'].isin(stores)) & (train['item'].isin(items))\n",
    "                    & (train['date'] >= start_date) & (train['date'] <= end_date)]\n",
    "\n",
    "val_merged = val_set.merge(predictions, on = ['store', 'item', 'date'])\n",
    "\n",
    "SMAPE(np.array(val_merged['sales_x']),val_merged['sales_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', 'year', 'store_1', 'store_2', 'store_3', 'store_4', 'store_5', 'store_6', 'store_7', 'store_8', 'store_9', 'store_10', 'item_1', 'item_2', 'item_3', 'item_4', 'item_5', 'item_6', 'item_7', 'item_8', 'item_9', 'item_10', 'item_11', 'item_12', 'item_13', 'item_14', 'item_15', 'item_16', 'item_17', 'item_18', 'item_19', 'item_20', 'item_21', 'item_22', 'item_23', 'item_24', 'item_25', 'item_26', 'item_27', 'item_28', 'item_29', 'item_30', 'item_31', 'item_32', 'item_33', 'item_34', 'item_35', 'item_36', 'item_37', 'item_38', 'item_39', 'item_40', 'item_41', 'item_42', 'item_43', 'item_44', 'item_45', 'item_46', 'item_47', 'item_48', 'item_49', 'item_50', 'day_of_week_0', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3', 'day_of_week_4', 'day_of_week_5', 'day_of_week_6', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
